{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "BrainMouse_Unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORlBH8h8maF1",
        "colab_type": "text"
      },
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJl7KYjFRgVw",
        "colab_type": "text"
      },
      "source": [
        "Pour faciliter l'import du dossier, et à cause du fait que l'environnement d'exécution est nettoyé après une déconnexion, nous avons importé le dossier dans notre Drive et nous avons établi une connexion avec notre notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwmdzHN-mdBR",
        "colab_type": "code",
        "outputId": "587a8ace-76ab-4ef7-d97a-944cfbb28dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /tensorflow-2.1.0/python3.6 (from google-api-python-client>=1.2->PyDrive) (1.11.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /tensorflow-2.1.0/python3.6 (from google-api-python-client>=1.2->PyDrive) (1.14.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /tensorflow-2.1.0/python3.6 (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /tensorflow-2.1.0/python3.6 (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /tensorflow-2.1.0/python3.6 (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.0.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /tensorflow-2.1.0/python3.6 (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3GAZNCLkyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgr6iKJ4L1C2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owdJbxtcMeVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1EEsjVZHlJpcP7ETpVIc02QEnWsa_1Ook'})\n",
        "download.GetContentFile('nifti.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6MmydR8PFRE",
        "colab_type": "code",
        "outputId": "6064ee70-c358-4ef1-f271-7a9c53008396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip nifti.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  nifti.zip\n",
            "   creating: nifti/\n",
            " extracting: nifti/.DS_Store         \n",
            "   creating: nifti/496/\n",
            " extracting: nifti/496/Shank_496-labels.atlas.xml  \n",
            " extracting: nifti/496/Shank_496-labels.nii  \n",
            " extracting: nifti/496/Shank_496.ibw.nii  \n",
            "   creating: nifti/497/\n",
            " extracting: nifti/497/Shank_497-labels.atlas.xml  \n",
            " extracting: nifti/497/Shank_497-labels.nii  \n",
            " extracting: nifti/497/Shank_497.ibw.nii  \n",
            "   creating: nifti/499/\n",
            " extracting: nifti/499/Shank_499-labels.atlas.xml  \n",
            " extracting: nifti/499/Shank_499-labels.nii  \n",
            " extracting: nifti/499/Shank_499.ibw.nii  \n",
            "   creating: nifti/506/\n",
            " extracting: nifti/506/Shank_506-labels.atlas.xml  \n",
            " extracting: nifti/506/Shank_506-labels.nii  \n",
            " extracting: nifti/506/Shank_506.ibw.nii  \n",
            "   creating: nifti/515/\n",
            " extracting: nifti/515/Shank_515-labels.atlas.xml  \n",
            " extracting: nifti/515/Shank_515-labels.nii  \n",
            " extracting: nifti/515/Shank_515.ibw.nii  \n",
            "   creating: nifti/520/\n",
            " extracting: nifti/520/Shank_520-labels.atlas.xml  \n",
            " extracting: nifti/520/Shank_520-labels.nii  \n",
            " extracting: nifti/520/Shank_520.ibw.nii  \n",
            "   creating: nifti/521/\n",
            " extracting: nifti/521/Shank_521-labels.atlas.xml  \n",
            " extracting: nifti/521/Shank_521-labels.nii  \n",
            " extracting: nifti/521/Shank_521.ibw.nii  \n",
            "   creating: nifti/522/\n",
            " extracting: nifti/522/Shank_522-labels.atlas.xml  \n",
            " extracting: nifti/522/Shank_522-labels.nii  \n",
            " extracting: nifti/522/Shank_522.ibw.nii  \n",
            "   creating: nifti/523/\n",
            " extracting: nifti/523/Shank_523-labels.atlas.xml  \n",
            " extracting: nifti/523/Shank_523-labels.nii  \n",
            " extracting: nifti/523/Shank_523.ibw.nii  \n",
            "   creating: nifti/527/\n",
            " extracting: nifti/527/Shank_527-labels.atlas.xml  \n",
            " extracting: nifti/527/Shank_527-labels.nii  \n",
            " extracting: nifti/527/Shank_527.ibw.nii  \n",
            "   creating: nifti/528/\n",
            " extracting: nifti/528/Shank_528-labels.atlas.xml  \n",
            " extracting: nifti/528/Shank_528-labels.nii  \n",
            " extracting: nifti/528/Shank_528.ibw.nii  \n",
            "   creating: nifti/534/\n",
            " extracting: nifti/534/Shank_534-labels.atlas.xml  \n",
            " extracting: nifti/534/Shank_534-labels.nii  \n",
            " extracting: nifti/534/Shank_534.ibw.nii  \n",
            "   creating: nifti/536/\n",
            " extracting: nifti/536/Shank_536-labels.atlas.xml  \n",
            " extracting: nifti/536/Shank_536-labels.nii  \n",
            " extracting: nifti/536/Shank_536.ibw.nii  \n",
            "   creating: nifti/541/\n",
            " extracting: nifti/541/Shank_541-labels.atlas.xml  \n",
            " extracting: nifti/541/Shank_541-labels.nii  \n",
            " extracting: nifti/541/Shank_541.ibw.nii  \n",
            "   creating: nifti/542/\n",
            " extracting: nifti/542/Shank_542-labels.atlas.xml  \n",
            " extracting: nifti/542/Shank_542-labels.nii  \n",
            " extracting: nifti/542/Shank_542.ibw.nii  \n",
            "   creating: nifti/550/\n",
            " extracting: nifti/550/Shank_550c-labels.atlas.xml  \n",
            " extracting: nifti/550/Shank_550c-labels.nii  \n",
            " extracting: nifti/550/Shank_550c.ibw.nii  \n",
            "   creating: nifti/data_test_sans_masque/\n",
            "   creating: nifti/data_test_sans_masque/498/\n",
            " extracting: nifti/data_test_sans_masque/498/Shank_498.ibw.nii  \n",
            "   creating: nifti/data_test_sans_masque/516/\n",
            " extracting: nifti/data_test_sans_masque/516/Shank_516.ibw.nii  \n",
            "   creating: nifti/nifti_em/\n",
            " extracting: nifti/nifti_em/.DS_Store  \n",
            " extracting: nifti/nifti_em/MetOD1_Day2.ibw.nii  \n",
            " extracting: nifti/nifti_em/MetOD1_Day21.ibw.nii  \n",
            " extracting: nifti/nifti_em/MetOD1_Day30.ibw.nii  \n",
            " extracting: nifti/nifti_em/MetOD1_Day35.ibw.nii  \n",
            " extracting: nifti/nifti_em/MetOG2_Day15.ibw.nii  \n",
            " extracting: nifti/nifti_em/MetOG2_Day24.ibw.nii  \n",
            "   creating: nifti/nifti_em/label/\n",
            " extracting: nifti/nifti_em/label/MetOD1_Day2-label.nii  \n",
            " extracting: nifti/nifti_em/label/MetOG2_Day15.ibw.nii.gz  \n",
            " extracting: nifti/nifti_em/label/MetOG2_Day24_segmentation.nii.gz  \n",
            " extracting: nifti/nifti_em/label/new_segmentation_MetOD1_Day30 (2).nii  \n",
            " extracting: nifti/nifti_em/label/new_segmentation_MetOD1_Day30.nii  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU0X2XeNRMK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf nifti/data_test_sans_masque/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyjEGFgKRO7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf nifti/nifti_em/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7aPoy18Co6c",
        "colab_type": "text"
      },
      "source": [
        "# **Mise en forme des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LUuc0b84__L",
        "colab_type": "code",
        "outputId": "19d21f67-4e81-47e1-985e-3e35cf41113a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#from future import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from keras import backend as K\n",
        "from nibabel.testing import data_path\n",
        "import nibabel as nib \n",
        "import matplotlib.pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import exposure, measure,transform\n",
        "from random import sample\n",
        "from tensorflow.python import math_ops\n",
        "import random\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "/device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkoQvx9HSVXj",
        "colab_type": "text"
      },
      "source": [
        "**Import des données**\n",
        "\n",
        "Nous utilisons le parcours hiérarchique de nos dossiers pour lire les fichiers, extraire la fdata et avoir les slices au même temps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x9psM-D4__b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "DATA = '/content/nifti/'\n",
        "\n",
        "data_feature, data_label = [], []\n",
        "for subdir,dirs, files in os.walk(DATA):\n",
        "    #print(\"\", os.listdir('.'))\n",
        "    for file in files:\n",
        "        name= os.path.join(subdir, file)\n",
        "        #print(\"\", name)\n",
        "        if name.endswith(\".nii\") :\n",
        "            if not (\"-labels\" in name):\n",
        "                img_data = nib.load(name).get_fdata()\n",
        "                for j in range(1,128):\n",
        "                    data_feature.append(img_data[:,:,j])\n",
        "                    data_feature.append(img_data[j,:,:])\n",
        "                    data_feature.append(img_data[:,j,:])\n",
        "\n",
        "            else:\n",
        "                label_data = nib.load(name).get_fdata()\n",
        "                for j in range(1,128):\n",
        "                    data_label.append(label_data[:,:,j])\n",
        "                    data_label.append(label_data[j,:,:])\n",
        "                    data_label.append(label_data[:,j,:])\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QShp03lndqf",
        "colab_type": "code",
        "outputId": "4079404b-cfcd-4c4f-ccd0-798cbf1198ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "range(1,len(data_feature))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(1, 6096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j4ZkZAmmPTb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Nous avons constaté que certains labels sont à 2 au lieu de 1, nous normalisons tous les labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKISd7s8jgKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_brain_label = []\n",
        "no_brain_feature = []\n",
        "\n",
        "for i in range(len(data_label)-1,0,-1):\n",
        "  has_brain = 0\n",
        "  for j in range(1,128):\n",
        "    for k in range(1,128):\n",
        "      if (data_label[i][j][k] > 1): \n",
        "        data_label[i][j][k] = 1.\n",
        "      if (data_label[i][j][k] == 1.):\n",
        "        has_brain=1\n",
        "  if (not has_brain):\n",
        "    no_brain_label.append(data_label.pop(i))\n",
        "    no_brain_feature.append(data_feature.pop(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMa0R4KTWX1u",
        "colab_type": "text"
      },
      "source": [
        "#**Modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60qGNtGqJRVo",
        "colab_type": "text"
      },
      "source": [
        "##Set input pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lho7Rw9nTCfs",
        "colab_type": "text"
      },
      "source": [
        "Extraire le jeu de données d'entraînement et de test à partir des Datasets initauxn en utilisant la fonction split de numpy. Nous avons choisi d'entraîner 80% des données.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBwf_7A7Bk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proportion = int(len(data_feature) * 0.8)\n",
        "\n",
        "#Split dataset  into train and test sets\n",
        "sub_data = np.split(data_feature, [ proportion, len(data_feature)])\n",
        "x_train = tf.expand_dims(tf.convert_to_tensor(sub_data[0], dtype = tf.float64), -1)\n",
        "x_test = tf.expand_dims(tf.convert_to_tensor(sub_data[1], dtype = tf.float64), -1) \n",
        "\n",
        "#Split labels into train and test\n",
        "sub_label = np.split(data_label, [ proportion, len(data_label)])\n",
        "y_train = tf.expand_dims(tf.convert_to_tensor(sub_label[0], dtype = tf.float32), -1)\n",
        "y_test = tf.expand_dims(tf.convert_to_tensor(sub_label[1], dtype = tf.float32), -1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgPBEaQ5Wnax",
        "colab_type": "text"
      },
      "source": [
        "Quelle est la taille de x_train ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRMmJq6R4__l",
        "colab_type": "code",
        "outputId": "632f9670-14e1-4ba1-feec-a7c99e204fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"x_train Shape: \", x_train.shape)\n",
        "print(\"y_train Shape: \", y_train.shape)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train Shape:  (2964, 128, 128, 1)\n",
            "y_train Shape:  (2964, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nqAI60ACTx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_data = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train), tf.data.Dataset.from_tensor_slices(y_train))).batch(BATCH_SIZE)\n",
        "test_data = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_test), tf.data.Dataset.from_tensor_slices(y_test))).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg6wMX-vCtCt",
        "colab_type": "text"
      },
      "source": [
        "## Couches\n",
        "\n",
        "On se base sur le modèle U-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH5N4YTU5AAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = (128,128,1)\n",
        "inputs = tf.keras.layers.Input(input_size)\n",
        "conv1 = tf.keras.layers.Conv2D(64, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "conv1 = tf.keras.layers.Conv2D(64, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = tf.keras.layers.Conv2D(128, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "conv2 = tf.keras.layers.Conv2D(128, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = tf.keras.layers.Conv2D(256, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "conv3 = tf.keras.layers.Conv2D(256, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = tf.keras.layers.Conv2D(512, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "conv4 = tf.keras.layers.Conv2D(512, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "drop4 = tf.keras.layers.Dropout(0.5)(conv4)\n",
        "pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "conv5 = tf.keras.layers.Conv2D(1024, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "conv5 = tf.keras.layers.Conv2D(1024, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "drop5 = tf.keras.layers.Dropout(0.5)(conv5)\n",
        "\n",
        "up6 = tf.keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(drop5))\n",
        "merge6 = tf.keras.layers.concatenate([drop4,up6], axis = 3)\n",
        "conv6 = tf.keras.layers.Conv2D(512, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "conv6 = tf.keras.layers.Conv2D(512, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "up7 = tf.keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv6))\n",
        "merge7 = tf.keras.layers.concatenate([conv3,up7], axis = 3)\n",
        "conv7 = tf.keras.layers.Conv2D(256, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "conv7 = tf.keras.layers.Conv2D(256, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "up8 = tf.keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv7))\n",
        "merge8 = tf.keras.layers.concatenate([conv2,up8], axis = 3)\n",
        "conv8 = tf.keras.layers.Conv2D(128, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "conv8 = tf.keras.layers.Conv2D(128, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "up9 = tf.keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv8))\n",
        "merge9 = tf.keras.layers.concatenate([conv1,up9], axis = 3)\n",
        "conv9 = tf.keras.layers.Conv2D(64, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "conv9 = tf.keras.layers.Conv2D(64, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = tf.keras.layers.Conv2D(2, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv10 = tf.keras.layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "unet = tf.keras.Model(inputs, conv10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S2D9A7-HSE-",
        "colab_type": "text"
      },
      "source": [
        "## Loss et metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8wm0ea_HWqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-6\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = pixel_wise_softmax(tf.keras.backend.flatten(y_pred))\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return -(2. * intersection) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cph-zGo1CxIV",
        "colab_type": "text"
      },
      "source": [
        "#**Entrainement**\n",
        "\n",
        "## callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcDytj_9Gl_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "    if epoch < 3:\n",
        "        return 1e-3\n",
        "    elif epoch >= 3 and epoch < 7:\n",
        "        return 1e-4\n",
        "    elif epoch >= 7 and epoch < 12:\n",
        "        return 1e-6\n",
        "    else:\n",
        "        return 1e-8\n",
        "\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      unet.optimizer.lr.numpy()))\n",
        "\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5, verbose=1)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR(),\n",
        "    earlystopper\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx-fGdPXTdZa",
        "colab_type": "text"
      },
      "source": [
        "Premier entraînement : Nous entraînons notre réseau avec le jeu de données initial, en utilisant dice_coef pour la loss et en rajoutant MeanIoU pour plus de visibilité sur la performance du réseau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Y-UIHK5AAL",
        "colab_type": "code",
        "outputId": "3ce2eec0-8d55-4bed-f4cc-9de014faa5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "unet.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4), \n",
        "              loss = dice_coef, \n",
        "              metrics = ['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "\n",
        "\n",
        "unet.fit(train_data, epochs=12, callbacks=callbacks, use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 47 steps\n",
            "Epoch 1/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -1.9440e-06 - accuracy: 0.1680 - mean_io_u_23: 0.0904\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "47/47 [==============================] - 18s 389ms/step - loss: -2.0352e-06 - accuracy: 0.1684 - mean_io_u_23: 0.0906\n",
            "Epoch 2/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -1.9894e-06 - accuracy: 0.2135 - mean_io_u_23: 0.1198\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.0850e-06 - accuracy: 0.2140 - mean_io_u_23: 0.1201\n",
            "Epoch 3/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.1549e-06 - accuracy: 0.4206 - mean_io_u_23: 0.2537\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.2653e-06 - accuracy: 0.4207 - mean_io_u_23: 0.2539\n",
            "Epoch 4/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.5319e-06 - accuracy: 0.6339 - mean_io_u_23: 0.4058\n",
            "Learning rate for epoch 4 is 9.999999747378752e-05\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.6685e-06 - accuracy: 0.6349 - mean_io_u_23: 0.4066\n",
            "Epoch 5/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.6756e-06 - accuracy: 0.7100 - mean_io_u_23: 0.4615\n",
            "Learning rate for epoch 5 is 9.999999747378752e-05\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.8148e-06 - accuracy: 0.7104 - mean_io_u_23: 0.4620\n",
            "Epoch 6/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.7564e-06 - accuracy: 0.7134 - mean_io_u_23: 0.4701\n",
            "Learning rate for epoch 6 is 9.999999747378752e-05\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.9014e-06 - accuracy: 0.7139 - mean_io_u_23: 0.4708\n",
            "Epoch 7/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.8114e-06 - accuracy: 0.7417 - mean_io_u_23: 0.4933\n",
            "Learning rate for epoch 7 is 9.999999747378752e-05\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.9566e-06 - accuracy: 0.7423 - mean_io_u_23: 0.4940\n",
            "Epoch 8/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.8421e-06 - accuracy: 0.7567 - mean_io_u_23: 0.5063\n",
            "Learning rate for epoch 8 is 9.999999974752427e-07\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.9877e-06 - accuracy: 0.7570 - mean_io_u_23: 0.5069\n",
            "Epoch 9/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.8501e-06 - accuracy: 0.7510 - mean_io_u_23: 0.5031\n",
            "Learning rate for epoch 9 is 9.999999974752427e-07\n",
            "47/47 [==============================] - 16s 344ms/step - loss: -2.9943e-06 - accuracy: 0.7513 - mean_io_u_23: 0.5037\n",
            "Epoch 10/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.8504e-06 - accuracy: 0.7493 - mean_io_u_23: 0.5021\n",
            "Learning rate for epoch 10 is 9.999999974752427e-07\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.9957e-06 - accuracy: 0.7497 - mean_io_u_23: 0.5027\n",
            "Epoch 11/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.8501e-06 - accuracy: 0.7468 - mean_io_u_23: 0.5004\n",
            "Learning rate for epoch 11 is 9.999999974752427e-07\n",
            "47/47 [==============================] - 16s 342ms/step - loss: -2.9969e-06 - accuracy: 0.7473 - mean_io_u_23: 0.5010\n",
            "Epoch 12/12\n",
            "46/47 [============================>.] - ETA: 0s - loss: -2.8497e-06 - accuracy: 0.7450 - mean_io_u_23: 0.4990\n",
            "Learning rate for epoch 12 is 9.999999974752427e-07\n",
            "47/47 [==============================] - 16s 343ms/step - loss: -2.9964e-06 - accuracy: 0.7454 - mean_io_u_23: 0.4997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa05bf23208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU0_Tjm9g1wD",
        "colab_type": "text"
      },
      "source": [
        "##Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB4_fUpM5AAV",
        "colab_type": "code",
        "outputId": "1395cd5c-ddf1-4650-cda6-3a3853186657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss = unet.evaluate(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "742/742 [==============================] - 2s 3ms/sample - loss: -5.6927e-06 - accuracy: 0.6576 - mean_io_u_23: 0.4348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUH1Bb1lB3Uc",
        "colab_type": "code",
        "outputId": "8e4b1ad0-3670-448e-90b3-ab01df051a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "\n",
        "#Plot expected result\n",
        "\n",
        "y_test_array = np.array(y_test)   \n",
        "print(\"Expected mask\")\n",
        "expected = y_test_array[10]\n",
        "matplotlib.pyplot.matshow(expected.reshape((128, 128)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected mask\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa3f66f8b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk+Egqen/ACA6LZzZirWXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2w73lyp3Edg",
        "colab_type": "code",
        "outputId": "1527f689-bd51-4986-bb73-f004e58e381f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "#plot our result\n",
        "\n",
        "print(\"What we got\")\n",
        "predicted = model.predict(x_test)\n",
        "model_result = predicted[10]\n",
        "matplotlib.pyplot.matshow(model_result.reshape((128, 128)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What we got\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa05f7869b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlpmIxivHUGE",
        "colab_type": "text"
      },
      "source": [
        "#**Résultats avec weights**\n",
        "Dans cette partie on va comparer l'entrainement de notre réseau avec un poids sur les pixels pour que le réseau de neuronne prenne plus en compte certaine parties que d'autres.\n",
        "\n",
        "## Définition des fonctions de poids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gAcyTIDmvU",
        "colab_type": "code",
        "outputId": "bcd485c5-1d49-44d7-edb4-a943c4394a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2964, 128, 128, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpGnUYlj0xw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#from https://github.com/ebouilhol/deepmeta/blob/master/weighted.py\n",
        "\n",
        "def weight_map(label, a, b):\n",
        "    \"\"\"\n",
        "    Création du carte de poids définissant une valeur d'importance pour chaque pixel\n",
        "    Les pixels n'appartenant pas au masque ont une valeur de poids définit à 1 par défaut\n",
        "    :param label: ensemble de x masque label 128x128\n",
        "    :param a: valeur du poids pour pixel appartenant au maque\n",
        "    :param b: valeur du poids pour pixel appartenant au contour du maque\n",
        "    :return: ensemble de y weight map 128x128\n",
        "    \"\"\"\n",
        "    weights = np.zeros((label.shape[0], 128, 128))\n",
        "\n",
        "    for k in np.arange(label.shape[0]):\n",
        "\n",
        "        lab = label[k]\n",
        "        contour = measure.find_contours(lab, 0.8)\n",
        "        indx_mask = np.where(lab == 1)[0]\n",
        "        indy_mask = np.where(lab == 1)[1]\n",
        "\n",
        "        w = np.ones((128, 128))\n",
        "        w[indx_mask, indy_mask] = a\n",
        "\n",
        "        for i in np.arange(len(contour)):\n",
        "            indx_cont = np.array(contour[i][:, 0], dtype='int')\n",
        "            indy_cont = np.array(contour[i][:, 1], dtype='int')\n",
        "            w[indx_cont, indy_cont] = b\n",
        "\n",
        "        #w = w ** 2\n",
        "        weights[k] = w\n",
        "\n",
        "    return(weights)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsroUxes4rMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_2D = weight_map(sub_label[0], 2, 4)\n",
        "\n",
        "data_2D = sub_data[0].reshape(-1, 128, 128, 1)\n",
        "label_2D = sub_label[0].reshape(-1, 128, 128, 1)\n",
        "weight_2D = weight_2D.reshape(-1, 128, 128, 1)\n",
        "\n",
        "y = np.zeros((data_2D.shape[0], 128, 128, 2))\n",
        "y[:, :, :, 0] = label_2D[:, :, :, 0]\n",
        "y[:, :, :, 1] = weight_2D[:, :, :, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOWJEqgprloP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/ebouilhol/deepmeta\n",
        "\n",
        "def weighted_cross_entropy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    -- Fonction de coût pondéré --\n",
        "    :param y_true: vrai valeur de y (label)\n",
        "    :param y_pred: valeur prédite de y par le modèle\n",
        "    :return: valeur de la fonction de cout d'entropie croisée pondérée\n",
        "    \"\"\"\n",
        "    try:\n",
        "        [seg, weight] = tf.unstack(y_true, 2, axis=3)\n",
        "\n",
        "        seg = tf.expand_dims(seg, -1)\n",
        "        weight = tf.expand_dims(weight, -1)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    epsilon = tf.convert_to_tensor(10e-8, y_pred.dtype.base_dtype)\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "    y_pred = tf.compat.v1.log(y_pred / (1 - y_pred))\n",
        "\n",
        "    zeros = tf.zeros_like(y_pred, dtype=y_pred.dtype)  #array_ops\n",
        "    cond = (y_pred >= zeros)\n",
        "    relu_logits = math_ops.select(cond, y_pred, zeros)\n",
        "    neg_abs_logits = math_ops.select(cond, -y_pred, y_pred)\n",
        "    entropy = math_ops.add(relu_logits - y_pred * seg, math_ops.log1p(math_ops.exp(neg_abs_logits)), name=None)\n",
        "    return K.mean(math_ops.multiply(weight, entropy), axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQo_PihgNuG",
        "colab_type": "text"
      },
      "source": [
        "##Entrainement du réseau\n",
        "###Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACwvo82K_ZXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay2(epoch):\n",
        "    if epoch < 3:\n",
        "        return 1e-3\n",
        "    elif epoch >= 3 and epoch < 7:\n",
        "        return 1e-4\n",
        "    elif epoch >= 7 and epoch < 12:\n",
        "        return 1e-6\n",
        "    else:\n",
        "        return 1e-8\n",
        "\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      unet.optimizer.lr.numpy()))\n",
        "\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5, verbose=1)\n",
        "\n",
        "\n",
        "callbacks2 = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay2),\n",
        "    PrintLR(),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7AVeY39gZlL",
        "colab_type": "code",
        "outputId": "af057361-56c3-4897-fca5-9ca8d02d09dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "unet_w  = tf.keras.Model(inputs, conv10)\n",
        "unet_w .compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4), \n",
        "              loss = weighted_cross_entropy,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "unet_w.fit(data_2D, y, epochs=12, callbacks=callbacks2, use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2964 samples\n",
            "Epoch 1/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3177 - accuracy: 0.4362\n",
            "Learning rate for epoch 1 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 18s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 2/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3105 - accuracy: 0.4363\n",
            "Learning rate for epoch 2 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 3/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3101 - accuracy: 0.4363\n",
            "Learning rate for epoch 3 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 4/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3171 - accuracy: 0.4362\n",
            "Learning rate for epoch 4 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 5/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3101 - accuracy: 0.4363\n",
            "Learning rate for epoch 5 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 6/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3110 - accuracy: 0.4363\n",
            "Learning rate for epoch 6 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 7/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3154 - accuracy: 0.4363\n",
            "Learning rate for epoch 7 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 8/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3151 - accuracy: 0.4363\n",
            "Learning rate for epoch 8 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 9/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3113 - accuracy: 0.4363\n",
            "Learning rate for epoch 9 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 10/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3180 - accuracy: 0.4362\n",
            "Learning rate for epoch 10 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 11/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3119 - accuracy: 0.4363\n",
            "Learning rate for epoch 11 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n",
            "Epoch 12/12\n",
            "2944/2964 [============================>.] - ETA: 0s - loss: 4.3166 - accuracy: 0.4362\n",
            "Learning rate for epoch 12 is 9.999999974752427e-07\n",
            "2964/2964 [==============================] - 17s 6ms/sample - loss: 4.3135 - accuracy: 0.4363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa05c593780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-L-5cLdvIK0",
        "colab_type": "code",
        "outputId": "a4b7ce52-6544-42b3-bf72-0f078f17149b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "weight_2D_test = weight_map(sub_label[1], 2, 4)\n",
        "\n",
        "data_2D_test = sub_data[1].reshape(-1, 128, 128, 1)\n",
        "label_2D_test = sub_label[1].reshape(-1, 128, 128, 1)\n",
        "weight_2D_test = weight_2D_test.reshape(-1, 128, 128, 1)\n",
        "\n",
        "y = np.zeros((data_2D_test.shape[0], 128, 128, 2))\n",
        "y[:, :, :, 0] = y_test[:, :, :, 0]\n",
        "y[:, :, :, 1] = weight_2D_test[:, :, :, 0]\n",
        "\n",
        "unet_w.evaluate(x_test, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "742/742 [==============================] - 2s 2ms/sample - loss: 0.7131 - accuracy: 0.4360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.713143563495492, 0.43600962]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em0eqdrVIf3e",
        "colab_type": "code",
        "outputId": "1add0a18-da42-483d-f56f-e2b774ba02ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "y = np.zeros((data_2D.shape[0], 128, 128, 2))\n",
        "y[:, :, :, 0] = label_2D[:, :, :, 0]\n",
        "y[:, :, :, 1] = weight_2D[:, :, :, 0]\n",
        "\n",
        "matplotlib.pyplot.matshow(y_train[2,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f36a5071a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4ZBRF2900C6",
        "colab_type": "code",
        "outputId": "01261179-7d26-4c09-863f-569a71ff7e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "print(\"Weight map\")\n",
        "\n",
        "weights = weight_2D[2]\n",
        "matplotlib.pyplot.matshow(weights.reshape((128, 128)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight map\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f36a5971518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSTPEcJDUZDhIajIcJDUZDpKa/h8qTO7I0J8k8gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc4ueb5CrsLz",
        "colab_type": "code",
        "outputId": "a32a42a0-2d47-40f2-8a6e-da0af65f5b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "print(\"What we got\")\n",
        "predicted_wei = unet_w.predict(x_test)\n",
        "model_weigh_result = predicted_wei[2]\n",
        "matplotlib.pyplot.matshow(model_weigh_result.reshape((128, 128)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What we got\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f36a47728d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPFbJkvr3nwp",
        "colab_type": "text"
      },
      "source": [
        "#Augmentation de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBkPlAOZ6xss",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Au début, nous avons essayé d'utiliser la classe ImageDataGenerator de Keras, mais nous n'avons pas pu avoir des résultats.  Nous avons donc décidé d'essayer quelques transformations de Tensorflow : Rotation et découpage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38WEzdWapIQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib.pyplot import imread, imshow, subplots, show\n",
        "\n",
        "#https://www.kaggle.com/shenmbsw/data-augmentation-and-tensorflow-u-net\n",
        "\n",
        "def aug_data(old_train, old_label,angel=30,resize_rate=1):\n",
        "\n",
        "    flip = random.randint(0, 1)\n",
        "    size = int(old_train.shape[0])\n",
        "    rsize = random.randint(np.floor(resize_rate*size),size)\n",
        "    w_s = random.randint(0,size - rsize)\n",
        "    h_s = random.randint(0,size - rsize)\n",
        "    sh = random.random()/2-0.25\n",
        "    rotate_angel = random.random()/180*np.pi*angel\n",
        "    \n",
        "\n",
        "    # Create Afine transform\n",
        "    afine_tf = transform.AffineTransform(shear=sh,rotation=rotate_angel)\n",
        "    # Randomly corpping image frame\n",
        "    old_train = old_train[w_s:w_s+size,h_s:h_s+size,:]\n",
        "    old_label = old_label[w_s:w_s+size,h_s:h_s+size]\n",
        "    # Ramdomly flip frame\n",
        "    if flip:\n",
        "        old_train = old_train[:,::-1,:]\n",
        "        old_label = old_label[:,::-1]\n",
        "    return old_train, old_label\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRjLjAzL8bKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train, new_label = aug_data(x_train, y_train)\n",
        "new_xtest, new_ytest = aug_data(x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVOR1Z17Mg-E",
        "colab_type": "text"
      },
      "source": [
        "Ici, on concatène l'ancien jeu d'entraînement et celui que nous avons obtenu après la fonction d'augmentation pour avoir un nouveau set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MuKQBaK5gyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = tf.concat([x_train,new_train],0)\n",
        "label = tf.concat([y_train,new_label],0)\n",
        "\n",
        "xtest = tf.concat([x_test, new_xtest],0)\n",
        "ytest = tf.concat([y_test, new_ytest],0)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train, label))\n",
        "dataset = dataset.batch(64).repeat()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FTcUlygBneJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay3(epoch):\n",
        "    if epoch < 3:\n",
        "        return 1e-3\n",
        "    elif epoch >= 3 and epoch < 7:\n",
        "        return 1e-4\n",
        "    elif epoch >= 7 and epoch < 12:\n",
        "        return 1e-6\n",
        "    else:\n",
        "        return 1e-8\n",
        "\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))\n",
        "\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5, verbose=1)\n",
        "\n",
        "\n",
        "callbacks3 = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay3),\n",
        "   \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qOzfUzH9Bc8",
        "colab_type": "code",
        "outputId": "96282795-f720-4eeb-bc6e-1dc11792d295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model_aug = tf.keras.Model(inputs, conv10)\n",
        "model_aug.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4), \n",
        "              loss = dice_coef, \n",
        "              metrics = ['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "\n",
        "\n",
        "model_aug.fit(dataset, epochs=12, steps_per_epoch=60,  use_multiprocessing=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 60 steps\n",
            "Epoch 1/12\n",
            "60/60 [==============================] - 23s 380ms/step - loss: -2.4533e-06 - accuracy: 0.7535 - mean_io_u_20: 0.5141\n",
            "Epoch 2/12\n",
            "60/60 [==============================] - 20s 341ms/step - loss: -2.4799e-06 - accuracy: 0.7554 - mean_io_u_20: 0.5152\n",
            "Epoch 3/12\n",
            "60/60 [==============================] - 21s 344ms/step - loss: -2.4594e-06 - accuracy: 0.7559 - mean_io_u_20: 0.5156\n",
            "Epoch 4/12\n",
            "60/60 [==============================] - 20s 341ms/step - loss: -2.4832e-06 - accuracy: 0.7472 - mean_io_u_20: 0.5093\n",
            "Epoch 5/12\n",
            "60/60 [==============================] - 20s 341ms/step - loss: -2.4849e-06 - accuracy: 0.7566 - mean_io_u_20: 0.5179\n",
            "Epoch 6/12\n",
            "60/60 [==============================] - 21s 343ms/step - loss: -2.4605e-06 - accuracy: 0.7620 - mean_io_u_20: 0.5208\n",
            "Epoch 7/12\n",
            "60/60 [==============================] - 20s 341ms/step - loss: -2.4869e-06 - accuracy: 0.7523 - mean_io_u_20: 0.5132\n",
            "Epoch 8/12\n",
            "60/60 [==============================] - 20s 341ms/step - loss: -2.4947e-06 - accuracy: 0.7587 - mean_io_u_20: 0.5190\n",
            "Epoch 9/12\n",
            "60/60 [==============================] - 21s 343ms/step - loss: -2.4632e-06 - accuracy: 0.7489 - mean_io_u_20: 0.5111\n",
            "Epoch 10/12\n",
            "60/60 [==============================] - 20s 340ms/step - loss: -2.4892e-06 - accuracy: 0.7565 - mean_io_u_20: 0.5161\n",
            "Epoch 11/12\n",
            "60/60 [==============================] - 20s 341ms/step - loss: -2.4982e-06 - accuracy: 0.7559 - mean_io_u_20: 0.5171\n",
            "Epoch 12/12\n",
            "60/60 [==============================] - 21s 343ms/step - loss: -2.4734e-06 - accuracy: 0.7607 - mean_io_u_20: 0.5205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3f614c128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgbsMIm6FseI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"What we got\")\n",
        "predicted_aug = model_aug.predict(x_test)\n",
        "model_aug_result = predicted_aug[64]\n",
        "matplotlib.pyplot.matshow(model_aug_result.reshape((128, 128)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDULrISmiDtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsqLihBbG03-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1avR4s1Fk6GG",
        "colab_type": "text"
      },
      "source": [
        "# **Augmentation avec des fenêtres**\n",
        "Ici on veut faire de la data augmentation à l'aide de fenêtre sur les images originales. \n",
        "\n",
        "Notre problème vient du fait qu'on ne veut pas mettre des images trop random dans notre jeu de données\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M_v7CE7XFE0",
        "colab_type": "text"
      },
      "source": [
        "##Réseau de test des fenêtres\n",
        "On entraine un réseau qui va nous servir à estimer si une fenêtre bonne ou pas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wAyuFnWk8ue",
        "colab_type": "code",
        "outputId": "daaa03ce-ea45-4387-9f8a-64c0f963673c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "  #Instantiate an empty model\n",
        "alexnet = tf.keras.Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "alexnet.add(tf.keras.layers.Conv2D(96, activation='relu', input_shape=(128,128,1), kernel_size=(11,11), strides=(4,4), padding='same', kernel_initializer = 'he_normal'))\n",
        "# Max Pooling\n",
        "alexnet.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "alexnet.add(tf.keras.layers.Conv2D(256, activation='relu',kernel_size=(11,11), strides=(1,1), padding='same', kernel_initializer = 'he_normal'))\n",
        "# Max Pooling\n",
        "alexnet.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "alexnet.add(tf.keras.layers.Conv2D(384, activation='relu',kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer = 'he_normal'))\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "alexnet.add(tf.keras.layers.Conv2D(384, activation='relu',kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "alexnet.add(tf.keras.layers.Conv2D(256, activation='relu',kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "# Max Pooling\n",
        "alexnet.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# Passing it to a Fully Connected layer\n",
        "alexnet.add(tf.keras.layers.Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "alexnet.add(tf.keras.layers.Dense(4096, activation='relu',input_shape=(224*224*3,)))\n",
        "# Add Dropout to prevent overfitting\n",
        "alexnet.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# 2nd Fully Connected Layer\n",
        "alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "# Add Dropout\n",
        "alexnet.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# 3rd Fully Connected Layer\n",
        "alexnet.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "# Add Dropout\n",
        "alexnet.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# Output Layer\n",
        "alexnet.add(tf.keras.layers.Dense(17, activation='softmax'))\n",
        "\n",
        "alexnet.summary()\n",
        "\n",
        "# Compile the model\n",
        "alexnet.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_129 (Conv2D)          (None, 32, 32, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_130 (Conv2D)          (None, 16, 16, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 8, 8, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_132 (Conv2D)          (None, 8, 8, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_133 (Conv2D)          (None, 8, 8, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 17)                17017     \n",
            "=================================================================\n",
            "Total params: 43,759,905\n",
            "Trainable params: 43,759,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nCIm8WmvTbf",
        "colab_type": "text"
      },
      "source": [
        "Pour les données on prend uniquement des images de cerveaux"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trEYGgrrvOyt",
        "colab_type": "code",
        "outputId": "f607f3ef-94e0-4c52-d0ee-0d9080e0f986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_label_f = data_label.copy()\n",
        "data_feature_f = data_feature.copy()\n",
        "\n",
        "\n",
        "for i in range(len(data_label)-1,0,-1):\n",
        "  number_brain = 0\n",
        "  for j in range(1,128):\n",
        "    for k in range(1,128):\n",
        "      if (data_label_f[i][j][k] > 1): \n",
        "        data_label[i][j][k] = 1.\n",
        "      if (data_label_f[i][j][k] == 1.):\n",
        "        number_brain+=1\n",
        "  if (number_brain<500):\n",
        "    data_label_f.pop(i)\n",
        "    data_feature_f.pop(i)\n",
        "len(data_feature_f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqyLRz6O0R2o",
        "colab_type": "text"
      },
      "source": [
        "Maintenant on a uniquement des images de cerveaux. On ajoute les noms images de cerveaux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m29Ij9ne0aXu",
        "colab_type": "code",
        "outputId": "901d21c5-0bb4-49f6-aad3-e8c1e8266e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "data_label_f = np.concatenate((np.ones((len(data_label_f))), np.zeros(len(no_brain_label))), axis=0)\n",
        "data_feature_f = np.concatenate((data_feature_f, no_brain_feature), axis=0)\n",
        "print(len(data_feature_f))\n",
        "print(len(data_label_f))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5662\n",
            "5662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv16VrxAAn1p",
        "colab_type": "code",
        "outputId": "1c33e45b-1607-4ac7-bb1a-82e0a263c073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_label_f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wc0Joj18ULT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "    \n",
        "data_label_f, data_feature_f = unison_shuffled_copies(data_label_f, data_feature_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEppkhkb69C9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proportion = int(len(data_feature_f) * 0.8)\n",
        "\n",
        "\n",
        "#Split dataset  into train and test sets\n",
        "sub_data_f = np.split(data_feature_f, [ proportion, len(data_feature_f)])\n",
        "x_train_f = tf.expand_dims(tf.convert_to_tensor(sub_data_f[0], dtype = tf.float64), -1)\n",
        "x_test_f = tf.expand_dims(tf.convert_to_tensor(sub_data_f[1], dtype = tf.float64), -1) \n",
        "\n",
        "#Split labels into train and test\n",
        "sub_label_f = np.split(data_label_f, [ proportion, len(data_label_f)])\n",
        "y_train_f = tf.expand_dims(tf.convert_to_tensor(sub_label_f[0], dtype = tf.int32), -1)\n",
        "y_test_f = tf.expand_dims(tf.convert_to_tensor(sub_label_f[1], dtype = tf.int32), -1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iemstxP9HTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_data_f = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train_f), tf.data.Dataset.from_tensor_slices(y_train_f))).batch(BATCH_SIZE)\n",
        "test_data_f = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_test_f), tf.data.Dataset.from_tensor_slices(y_test_f))).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCqBOwv8Ac3y",
        "colab_type": "code",
        "outputId": "c4b07e3d-5f12-4433-bf56-55974fd93c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 128, 128, 1), (None, 1)), types: (tf.float64, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcDhIYqupjhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay_f(epoch):\n",
        "    if epoch < 3:\n",
        "        return 1e-3\n",
        "    elif epoch >= 3 and epoch < 7:\n",
        "        return 1e-4\n",
        "    elif epoch >= 7 and epoch < 12:\n",
        "        return 1e-6\n",
        "    else:\n",
        "        return 1e-8\n",
        "\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))\n",
        "\n",
        "\n",
        "callbacks_f = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay_f),\n",
        "    PrintLR(),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxR9Tq-ItDbm",
        "colab_type": "code",
        "outputId": "9971d1f3-0df9-423c-d101-31026f1b63a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "alexnet.fit(train_data_f, epochs=12, callbacks=callbacks_f, use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 71 steps\n",
            "Epoch 1/12\n",
            "69/71 [============================>.] - ETA: 0s - loss: 8.7736 - accuracy: 0.4309\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "71/71 [==============================] - 2s 24ms/step - loss: 8.7731 - accuracy: 0.4309\n",
            "Epoch 2/12\n",
            "70/71 [============================>.] - ETA: 0s - loss: 8.7699 - accuracy: 0.4311\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "71/71 [==============================] - 2s 24ms/step - loss: 8.7726 - accuracy: 0.4309\n",
            "Epoch 3/12\n",
            "70/71 [============================>.] - ETA: 0s - loss: 8.7707 - accuracy: 0.4311\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "71/71 [==============================] - 2s 24ms/step - loss: 8.7733 - accuracy: 0.4309\n",
            "Epoch 4/12\n",
            "70/71 [============================>.] - ETA: 0s - loss: 8.7697 - accuracy: 0.4311\n",
            "Learning rate for epoch 4 is 0.0010000000474974513\n",
            "71/71 [==============================] - 2s 25ms/step - loss: 8.7723 - accuracy: 0.4309\n",
            "Epoch 5/12\n",
            "70/71 [============================>.] - ETA: 0s - loss: 8.7700 - accuracy: 0.4311\n",
            "Learning rate for epoch 5 is 0.0010000000474974513\n",
            "71/71 [==============================] - 2s 25ms/step - loss: 8.7726 - accuracy: 0.4309\n",
            "Epoch 6/12\n",
            "30/71 [===========>..................] - ETA: 1s - loss: 8.9125 - accuracy: 0.4219\n",
            "Learning rate for epoch 6 is 0.0010000000474974513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-223-e8585cd0e888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malexnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDfPpgAshkiS",
        "colab_type": "text"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HdgAogSXp0l",
        "colab_type": "text"
      },
      "source": [
        "## Augmentation avec les fenêtres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pjNnIvUXsup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}